# Model API configuration (reference model.yaml for full settings)
# Override specific settings here if needed
api:
  # Inherits from model.yaml, can override here
  # base_url: "..."
  # api_key: "..."
  pass

# Prompt templates
prompts:
  global_prefix: "This is an algorithm function.\n\n"
  
  # Function name generation (Stage A)
  funcname:
    fim:
      prefix: "This is an algorithm function.\n\ndef "
      suffix: "():\n"
    l2r:
      prompt: "This is an algorithm function.\n\ndef "
  
  # Code generation (Stage B)
  codegen:
    template: |
      This is an algorithm function.

      def {func_name}():
          """
          {description}
          """

namegen:
  temperature: 0.4
  top_p: 0.9
  max_new_tokens: 16
  n: 4  # Number of samples per batch
  num_batches: 2  # Number of batches (total samples = n * num_batches)
  stop: ["(", " ", "\n"]
  weaklist: 
    - "foo"
    - "bar"
    - "tmp"
    - "test"
    - "func"
    - "function"
    - "my_func"
    - "main"
    - "solution"
    - "answer"
    - "example"
    - "sample"

codegen:
  temperature: 0.3
  top_p: 0.9
  max_new_tokens: 512
  n: 4

filters:
  name_regex: "^[a-z_][a-z0-9_]{2,64}$"
  min_code_len: 16
  enable_ast: true
  enable_ruff: false

io:
  input_desc_path: "data/processed/descriptions.jsonl"
  out_names_dir: "data/generated/names"
  out_code_dir: "data/generated/code"
  shard_size: 2000

# Model configuration reference
# See configs/model.yaml for full model settings
model_config: "configs/model.yaml"

